{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_04_Quantization.ipynb","provenance":[{"file_id":"11xQTsGWASrUIQE3usoaDRzNG_rofchsL","timestamp":1615395403638}],"collapsed_sections":[],"authorship_tag":"ABX9TyPCtucvqXN5ACzLll/XCE/5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y2fkP_np3Zpl"},"source":["<!--BOOK_INFORMATION-->\n","<img align=\"left\" style=\"width:80px;height:98px;padding-right:20px;\" src=\"https://raw.githubusercontent.com/joe-papa/pytorch-book/main/files/pytorch-book-cover.jpg\">\n","\n","This notebook contains an excerpt from the [PyTorch Pocket Reference](http://pytorchbook.com) book by [Joe Papa](http://joepapa.ai); content is available [on GitHub](https://github.com/joe-papa/pytorch-book)."]},{"cell_type":"markdown","metadata":{"id":"q5mAsVfYHXc9"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joe-papa/pytorch-book/blob/main/06_04_Quantization.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"aXkszegKMMMn"},"source":["# Chapter 6 - PyTorch Acceleration & Optimization"]},{"cell_type":"markdown","metadata":{"id":"uH4vxoDR_5Rf"},"source":["We use CPU backend for this example"]},{"cell_type":"markdown","metadata":{"id":"h7CZcpKsHpCv"},"source":["### Quantization"]},{"cell_type":"code","metadata":{"id":"K-50OMzx_ykl"},"source":["import torch \n","from torch import nn\n","import torch.nn.functional as F\n","\n","class LeNet5(nn.Module):\n","    def __init__(self):\n","        super(LeNet5, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(\n","            F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(\n","            F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, \n","                   int(x.nelement() / x.shape[0]))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","model = LeNet5()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QV8fqM6kDCes","executionInfo":{"status":"ok","timestamp":1615480616708,"user_tz":300,"elapsed":511,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}},"outputId":"a28f1572-552d-4283-877c-05d947a43b26"},"source":["for n, p in model.named_parameters():\n","  print(n, \": \", p.dtype)\n","\n","# out:\n","# conv1.weight :  torch.float32\n","# conv1.bias :  torch.float32\n","# conv2.weight :  torch.float32\n","# conv2.bias :  torch.float32\n","# fc1.weight :  torch.float32\n","# fc1.bias :  torch.float32\n","# fc2.weight :  torch.float32\n","# fc2.bias :  torch.float32\n","# fc3.weight :  torch.float32\n","# fc3.bias :  torch.float32"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conv1.weight :  torch.float32\n","conv1.bias :  torch.float32\n","conv2.weight :  torch.float32\n","conv2.bias :  torch.float32\n","fc1.weight :  torch.float32\n","fc1.bias :  torch.float32\n","fc2.weight :  torch.float32\n","fc2.bias :  torch.float32\n","fc3.weight :  torch.float32\n","fc3.bias :  torch.float32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCNgfh4ZARjB","executionInfo":{"status":"ok","timestamp":1615481427346,"user_tz":300,"elapsed":488,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}},"outputId":"a1a2f8ed-7722-4f1b-9215-f3869006819b"},"source":["model = model.half()\n","\n","for n, p in model.named_parameters():\n","  print(n, \": \", p.dtype)\n","\n","# out: \n","# conv1.weight :  torch.float16\n","# conv1.bias :  torch.float16\n","# conv2.weight :  torch.float16\n","# conv2.bias :  torch.float16\n","# fc1.weight :  torch.float16\n","# fc1.bias :  torch.float16\n","# fc2.weight :  torch.float16\n","# fc2.bias :  torch.float16\n","# fc3.weight :  torch.float16\n","# fc3.bias :  torch.float16"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conv1.weight :  torch.float16\n","conv1.bias :  torch.float16\n","conv2.weight :  torch.float16\n","conv2.bias :  torch.float16\n","fc1.weight :  torch.float16\n","fc1.bias :  torch.float16\n","fc2.weight :  torch.float16\n","fc2.bias :  torch.float16\n","fc3.weight :  torch.float16\n","fc3.bias :  torch.float16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t2_E05bz_jiC"},"source":["import torch.quantization\n","\n","quantized_model = \\\n","  torch.quantization.quantize_dynamic(\n","      model, \n","      {torch.nn.Linear},\n","      dtype=torch.qint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFpUlm6SFQju","executionInfo":{"status":"ok","timestamp":1615480621452,"user_tz":300,"elapsed":628,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}},"outputId":"6ebe9dab-c506-4468-af3f-ba5e7478ac1e"},"source":["static_quant_model = LeNet5()\n","static_quant_model.qconfig = \\\n","  torch.quantization.get_default_qconfig('fbgemm')\n","\n","torch.quantization.prepare(\n","    static_quant_model, inplace=True)\n","torch.quantization.convert(\n","    static_quant_model, inplace=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n","  reduce_range will be deprecated in a future release of PyTorch.\"\n","/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:957: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n","  Returning default scale and zero point \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LeNet5(\n","  (conv1): QuantizedConv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0)\n","  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0)\n","  (fc1): QuantizedLinear(in_features=400, out_features=120, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n","  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n","  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6-4fBVKG94G","executionInfo":{"status":"ok","timestamp":1615480637538,"user_tz":300,"elapsed":451,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}},"outputId":"1305d2aa-adef-47ff-93f0-b9e260a44c7b"},"source":["qat_model = LeNet5()\n","qat_mode.qconfig = \\\n","  torch.quantization.get_default_qat_qconfig('fbgemm')\n","\n","torch.quantization.prepare_qat(\n","    qat_model, inplace=True)\n","torch.quantization.convert(\n","    qat_model, inplace=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py:244: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n","  warnings.warn(\"None of the submodule got qconfig applied. Make sure you \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LeNet5(\n","  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"B-Cx_V83JSeA"},"source":[""],"execution_count":null,"outputs":[]}]}