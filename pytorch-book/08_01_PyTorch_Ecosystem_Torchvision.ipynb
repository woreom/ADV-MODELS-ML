{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_01_PyTorch_Ecosystem_Torchvision.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNg70bWiCPQ4duNkBgObtcy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y2fkP_np3Zpl"},"source":["<!--BOOK_INFORMATION-->\n","<img align=\"left\" style=\"width:80px;height:98px;padding-right:20px;\" src=\"https://raw.githubusercontent.com/joe-papa/pytorch-book/main/files/pytorch-book-cover.jpg\">\n","\n","This notebook contains an excerpt from the [PyTorch Pocket Reference](http://pytorchbook.com) book by [Joe Papa](http://joepapa.ai); content is available [on GitHub](https://github.com/joe-papa/pytorch-book)."]},{"cell_type":"markdown","metadata":{"id":"IfSWo52KIahc"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joe-papa/pytorch-book/blob/main/08_01_PyTorch_Ecosystem_Torchvision.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"yw9xjxnv7KUZ"},"source":["# Chapter 8 - PyTorch Ecosystem"]},{"cell_type":"markdown","metadata":{"id":"r_1VNkK15aEC"},"source":["## Torchvision for Image & Video"]},{"cell_type":"markdown","metadata":{"id":"uf2E3-cC7KUt"},"source":["### Datasets & IO"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"id":"VV1aQg9S7KUt","executionInfo":{"status":"error","timestamp":1618600986604,"user_tz":240,"elapsed":4206,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}},"outputId":"c11efc45-a7b8-494b-f99e-79515052e138"},"source":["import torchvision.datasets as datasets\n","train_data = datasets.CIFAR10(\n","                root=\".\", \n","                train=True, \n","                transform=None,\n","                download=True)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8c90b7803d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m train_data = datasets.CIFAR10(\n\u001b[1;32m      3\u001b[0m                 \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVOCSegmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCDetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcityscapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimagenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcaltech\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaltech101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCaltech256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mceleba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCelebA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"lvgVTqeO4mjV"},"source":["### Models"]},{"cell_type":"code","metadata":{"id":"eIPe5f3i7KUw","executionInfo":{"status":"aborted","timestamp":1618600986602,"user_tz":240,"elapsed":4201,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}}},"source":["import torchvision.models as models\n","\n","model = models.vgg16(pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAzutbWW4r-c"},"source":["### Transforms, Operations, and Utilities"]},{"cell_type":"code","metadata":{"id":"284USGRC4jCX","executionInfo":{"status":"aborted","timestamp":1618600986603,"user_tz":240,"elapsed":4201,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"}}},"source":["from torchvision import transforms, datasets\n","\n","train_transforms = transforms.Compose([\n","                      transforms.ToTensor(),\n","                      transforms.Normalize(\n","                      (0.4914, 0.4822, 0.4465),\n","                      (0.2023, 0.1994, 0.2010)),\n","                      ])\n","train_data = datasets.CIFAR10(\n","                  root=\".\", \n","                  train=True,\n","                  transform=train_transforms)"],"execution_count":null,"outputs":[]}]}